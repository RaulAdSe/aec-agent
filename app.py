"""
AEC Compliance Agent - Streamlit Web Interface
Main entry point for the Streamlit application.
"""

import streamlit as st
import os
from pathlib import Path

# Set page config
st.set_page_config(
    page_title="AEC Compliance Agent",
    page_icon="ğŸ—ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

def main():
    """Main Streamlit application."""
    st.title("ğŸ—ï¸ AEC Compliance Agent")
    st.markdown("**Architecture, Engineering & Construction Compliance Assistant**")
    
    # Initialize session state for chat
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Create two columns for upload sections
    col1, col2 = st.columns(2)
    
    with col1:
        show_ifc_upload_section()
    
    with col2:
        show_legal_docs_upload_section()
    
    # Chat interface
    show_chat_interface()

def show_ifc_upload_section():
    """Display IFC file upload section."""
    st.subheader("ğŸ“Š IFC Building Models")
    
    with st.container():
        st.markdown("""
        <div style="
            border: 2px dashed #ccc;
            border-radius: 10px;
            padding: 20px;
            text-align: center;
            background-color: #f9f9f9;
            margin-bottom: 10px;
        ">
            <p style="margin: 0; color: #666;">
                ğŸ—ï¸ Drop IFC files here or click to browse
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        uploaded_ifc = st.file_uploader(
            "Upload IFC Files",
            type=['ifc'],
            accept_multiple_files=True,
            key="ifc_uploader",
            label_visibility="collapsed"
        )
        
        if uploaded_ifc:
            st.success(f"âœ… {len(uploaded_ifc)} IFC file(s) uploaded")
            for file in uploaded_ifc:
                st.write(f"ğŸ“„ {file.name} ({file.size} bytes)")
                # Placeholder for processing logic
                st.info("*Processing logic will be implemented in ifc-upload-feature branch*")

def show_legal_docs_upload_section():
    """Display legal documents upload section."""
    st.subheader("ğŸ“š Legal Documentation")
    
    with st.container():
        st.markdown("""
        <div style="
            border: 2px dashed #ccc;
            border-radius: 10px;
            padding: 20px;
            text-align: center;
            background-color: #f9f9f9;
            margin-bottom: 10px;
        ">
            <p style="margin: 0; color: #666;">
                ğŸ“„ Drop PDF documents here or click to browse
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        uploaded_pdfs = st.file_uploader(
            "Upload Legal Documents",
            type=['pdf'],
            accept_multiple_files=True,
            key="pdf_uploader",
            label_visibility="collapsed"
        )
        
        if uploaded_pdfs:
            st.success(f"âœ… {len(uploaded_pdfs)} PDF file(s) uploaded")
            for file in uploaded_pdfs:
                st.write(f"ğŸ“„ {file.name} ({file.size} bytes)")
                # Placeholder for processing logic
                st.info("*Processing logic will be implemented in pdf-upload-rag branch*")

def show_chat_interface():
    """Display the chat interface."""
    st.divider()
    st.subheader("ğŸ’¬ Chat Assistant")
    
    # Display chat messages
    chat_container = st.container()
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    # Chat input
    if prompt := st.chat_input("Ask about compliance, regulations, or your uploaded files..."):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # Display user message
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Generate assistant response (placeholder)
        with st.chat_message("assistant"):
            response = generate_response(prompt)
            st.markdown(response)
        
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": response})

def generate_response(prompt):
    """Generate response to user prompt."""
    # Placeholder response logic - will be implemented with agent integration
    if "ifc" in prompt.lower():
        return "I can help you analyze IFC building models for compliance. Please upload your IFC files using the upload section above, and I'll process them for analysis."
    elif "regulation" in prompt.lower() or "legal" in prompt.lower():
        return "For regulatory compliance questions, I can reference the legal documents you've uploaded. Please add relevant PDF documents to enhance my knowledge base."
    else:
        return f"I understand you're asking about: '{prompt}'. I'm ready to help with AEC compliance questions. Upload your IFC models and legal documents to get started with detailed analysis."

if __name__ == "__main__":
    main()