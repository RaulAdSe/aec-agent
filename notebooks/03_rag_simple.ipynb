{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Tutorial 3: RAG - Query Building Codes with AI\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "- What is RAG (Retrieval Augmented Generation)\n",
    "- How to query Spanish building codes (CTE)\n",
    "- See actual retrieved chunks with scores\n",
    "- Compare with/without RAG\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§î What is RAG?\n",
    "\n",
    "**Problem**: LLMs don't know about:\n",
    "- Your company's documents\n",
    "- Recent information\n",
    "- Specific building codes\n",
    "\n",
    "**Solution**: RAG = Retrieval + Generation\n",
    "\n",
    "```\n",
    "User Question\n",
    "     ‚Üì\n",
    "üîç Search Documents (Retrieval)\n",
    "     ‚Üì\n",
    "üìÑ Find Relevant Chunks\n",
    "     ‚Üì\n",
    "ü§ñ LLM + Context ‚Üí Answer (Generation)\n",
    "```\n",
    "\n",
    "We have Spanish building codes (CTE):\n",
    "- **CTE DB-SI**: Seguridad en caso de incendio\n",
    "- **CTE DB-SUA**: Seguridad de utilizaci√≥n y accesibilidad\n",
    "\n",
    "Total: ~200 pages of regulations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß≠ Tutorial Structure\n",
    "\n",
    "- **Baseline**: LLM without RAG (shows generic responses)\n",
    "- **Part 1**: Keyword-only search on TXT (`data/normativa/cte_db_si_ejemplo.txt`)\n",
    "- **Part 2**: Hybrid retrieval + reranker using embedded PDF (`data/normativa/DBSI.pdf`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook auto-loads the vectorstore for Part 2. If it doesn't exist, it will create it from `data/normativa/DBSI.pdf`.\n",
    "\n",
    "**If you get Chroma instance conflicts, restart the kernel and run all cells again.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Basic setup complete!\n",
      "   Project root: /Users/rauladell/Work/Servitec/aec-compliance-agent\n",
      "   Working directory: /Users/rauladell/Work/Servitec/aec-compliance-agent/notebooks\n",
      "   OpenAI API key: ‚úÖ Found\n",
      "‚ö†Ô∏è Part 2 (vectorstore) not available: No module named 'langchain_core.memory'\n",
      "   Error type: ModuleNotFoundError\n",
      "   Part 1 (TXT search) will still work\n",
      "\n",
      "üéØ Ready to start!\n",
      "   Baseline: LLM without RAG\n",
      "   Part 1: TXT keyword search (always works)\n",
      "   Part 2: PDF hybrid retrieval (if vectorstore loaded)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Ensure project root is on sys.path so `src` is importable, even if kernel starts in notebooks/\n",
    "ROOT = Path.cwd()\n",
    "try:\n",
    "    # Walk up until we find a folder containing `src`\n",
    "    while ROOT != ROOT.parent and not (ROOT / 'src').exists():\n",
    "        ROOT = ROOT.parent\n",
    "finally:\n",
    "    if (ROOT / 'src').exists() and str(ROOT) not in sys.path:\n",
    "        sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import textwrap\n",
    "\n",
    "print(\"‚úÖ Basic setup complete!\")\n",
    "print(f\"   Project root: {ROOT}\")\n",
    "print(f\"   Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Check API key\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"   OpenAI API key: ‚úÖ Found\")\n",
    "else:\n",
    "    print(\"   OpenAI API key: ‚ùå Not found in .env\")\n",
    "\n",
    "# Try to load vectorstore for Part 2 (optional)\n",
    "rag = None\n",
    "try:\n",
    "    from src.rag.vectorstore_manager import VectorstoreManager\n",
    "    \n",
    "    # Clear any existing vectorstore to avoid conflicts\n",
    "    import shutil\n",
    "    vectorstore_path = ROOT / \"vectorstore/normativa_db\"\n",
    "    if vectorstore_path.exists():\n",
    "        shutil.rmtree(vectorstore_path)\n",
    "        print(\"   Cleared existing vectorstore\")\n",
    "    \n",
    "    # Create new vectorstore\n",
    "    print(\"   Creating vectorstore from PDFs...\")\n",
    "    rag = VectorstoreManager(vectorstore_path)\n",
    "    rag.create_from_pdfs(ROOT / \"data/normativa\")\n",
    "    print(\"   Loading vectorstore...\")\n",
    "    rag.load_existing()\n",
    "    \n",
    "    # Test it works\n",
    "    print(\"   Testing vectorstore...\")\n",
    "    test_docs = rag.vectorstore.similarity_search(\"test\", k=1)\n",
    "    print(f\"‚úÖ Part 2 ready! Found {len(test_docs)} docs in vectorstore\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Part 2 (vectorstore) not available: {e}\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    if \"tenants\" in str(e) or \"Database error\" in str(e):\n",
    "        print(\"   üí° This is a ChromaDB schema issue. The vectorstore directory has been cleared.\")\n",
    "        print(\"   üí° Try restarting the kernel and running all cells again.\")\n",
    "    print(\"   Part 1 (TXT search) will still work\")\n",
    "    rag = None\n",
    "\n",
    "print(\"\\nüéØ Ready to start!\")\n",
    "print(\"   Baseline: LLM without RAG\")\n",
    "print(\"   Part 1: TXT keyword search (always works)\")\n",
    "print(\"   Part 2: PDF hybrid retrieval (if vectorstore loaded)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Baseline: LLM WITHOUT RAG\n",
      "======================================================================\n",
      "\n",
      "‚ùì ¬øAncho m√≠nimo de puerta de evacuaci√≥n?\n",
      "--------------------------------------------------\n",
      "üìù Respuesta: Seg√∫n la normativa espa√±ola, el ancho m√≠nimo de una puerta de evacuaci√≥n en edificios destinados a uso residencial es de 0,80 metros. Este ancho garantiza que una persona pueda salir con facilidad en caso de emergencia. Es importante cumplir con esta medida para garantizar la seguridad de los ocupantes del edificio.\n",
      "\n",
      "‚ùì ¬øDistancia m√°xima de evacuaci√≥n en edificios?\n",
      "--------------------------------------------------\n",
      "üìù Respuesta: La distancia m√°xima de evacuaci√≥n en edificios en Espa√±a suele estar regulada por la normativa de prevenci√≥n de incendios, que puede variar seg√∫n la normativa auton√≥mica correspondiente. En general, se establece que la distancia m√°xima de evacuaci√≥n en un edificio no debe superar los 50 metros desde cualquier punto del edificio hasta la salida de evacuaci√≥n m√°s cercana. Es importante tener en cuenta que esta distancia puede variar dependiendo del tipo de edificio, su uso y la normativa espec√≠fica aplicable en cada caso. Es recomendable consultar la normativa vigente en cada comunidad aut√≥noma para obtener informaci√≥n m√°s detallada al respecto.\n",
      "\n",
      "======================================================================\n",
      "üîç Now let's see how RAG improves these answers...\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Baseline: Test LLM WITHOUT RAG (shows generic responses)\n",
    "print(\"ü§ñ Baseline: LLM WITHOUT RAG\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI()\n",
    "        \n",
    "        questions = [\n",
    "            \"¬øAncho m√≠nimo de puerta de evacuaci√≥n?\",\n",
    "            \"¬øDistancia m√°xima de evacuaci√≥n en edificios?\"\n",
    "        ]\n",
    "        \n",
    "        for q in questions:\n",
    "            print(f\"\\n‚ùì {q}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Eres un experto en normativa de construcci√≥n espa√±ola. Responde bas√°ndote en tu conocimiento general.\"},\n",
    "                    {\"role\": \"user\", \"content\": q}\n",
    "                ],\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            answer = response.choices[0].message.content\n",
    "            print(f\"üìù Respuesta: {answer}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en LLM: {e}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Set OPENAI_API_KEY to see LLM responses without RAG\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîç Now let's see how RAG improves these answers...\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "üîé Part 1: Keyword-only Search (TXT)\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "‚ùì ¬øAncho m√≠nimo de puerta de evacuaci√≥n?\n",
      "======================================================================\n",
      "üîç STEP 1: Retrieval Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "          .cards { display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); gap: 12px; }\n",
       "          .card { border: 1px solid #e5e7eb; border-radius: 8px; padding: 12px; background: #fff; }\n",
       "          .card-title { font-weight: 600; margin-bottom: 6px; }\n",
       "          .card-meta { color: #6b7280; font-size: 12px; margin-bottom: 8px; }\n",
       "          .card-body { font-size: 14px; line-height: 1.4; }\n",
       "        </style>\n",
       "        <div class='cards'>\n",
       "          \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 1 ‚Äî Score 3.375</div>\n",
       "                <div class='card-meta'>Source: cte_db_si_ejemplo.txt ‚Äî Section: SECCI√ìN 3</div>\n",
       "                <div class='card-body'>SECCI√ìN 3: EVACUACI√ìN DE OCUPANTES 3.1 ANCHOS M√çNIMOS DE PUERTAS 3.1.1 Puertas de evacuaci√≥n Las puertas de evacuaci√≥n tendr√°n un ancho libre m√≠nimo de 0,80 m, excepto las puertas de evacuaci√≥n de locales con ocupaci√≥n inferior a 50 personas, que podr√°n tener un ancho libre m√≠nimo de 0,60 m. 3.1.2 Puertas de salida de emergencia Las puertas de salida de emergencia tendr√°n un...</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 2 ‚Äî Score 0.000</div>\n",
       "                <div class='card-meta'>Source: cte_db_si_ejemplo.txt</div>\n",
       "                <div class='card-body'>C√ìDIGO T√âCNICO DE LA EDIFICACI√ìN DOCUMENTO B√ÅSICO DB-SI: SEGURIDAD EN CASO DE INCENDIO SECCI√ìN</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 3 ‚Äî Score 0.000</div>\n",
       "                <div class='card-meta'>Source: cte_db_si_ejemplo.txt ‚Äî Section: SECCI√ìN 4</div>\n",
       "                <div class='card-body'>SECCI√ìN 4: COMPARTIMENTACI√ìN 4.1 SECTORES DE INCENDIO Los edificios se dividir√°n en sectores de incendio mediante elementos constructivos con resistencia al fuego adecuada. 4.2 PUERTAS RESISTENTES AL FUEGO Las puertas que comuniquen sectores de incendio diferentes tendr√°n una resistencia al fuego m√≠nima de 30 minutos (RF-30). SECCI√ìN</div>\n",
       "            </div>\n",
       "            \n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ STEP 2: LLM Response\n",
      "üìù Respuesta: Las puertas de evacuaci√≥n tendr√°n un ancho libre m√≠nimo de 0,80 m, excepto las puertas de evacuaci√≥n de locales con ocupaci√≥n inferior a 50 personas, que podr√°n tener un ancho libre m√≠nimo de 0,60 m.\n",
      "\n",
      "Fuente: \"SECCI√ìN 3: EVACUACI√ìN DE OCUPANTES ‚Äî 3.1.1 Puertas de evacuaci√≥n: Las puertas de evacuaci√≥n tendr√°n un ancho libre m√≠nimo de 0,80 m, excepto las puertas de evacuaci√≥n de locales con ocupaci√≥n inferior a 50 personas, que podr√°n tener un ancho libre m√≠nimo de 0,60 m.\"\n",
      "\n",
      "======================================================================\n",
      "‚ùì ¬øDistancia m√°xima de evacuaci√≥n?\n",
      "======================================================================\n",
      "üîç STEP 1: Retrieval Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "          .cards { display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); gap: 12px; }\n",
       "          .card { border: 1px solid #e5e7eb; border-radius: 8px; padding: 12px; background: #fff; }\n",
       "          .card-title { font-weight: 600; margin-bottom: 6px; }\n",
       "          .card-meta { color: #6b7280; font-size: 12px; margin-bottom: 8px; }\n",
       "          .card-body { font-size: 14px; line-height: 1.4; }\n",
       "        </style>\n",
       "        <div class='cards'>\n",
       "          \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 1 ‚Äî Score 3.500</div>\n",
       "                <div class='card-meta'>Source: cte_db_si_ejemplo.txt ‚Äî Section: SECCI√ìN 3</div>\n",
       "                <div class='card-body'>SECCI√ìN 3: EVACUACI√ìN DE OCUPANTES 3.1 ANCHOS M√çNIMOS DE PUERTAS 3.1.1 Puertas de evacuaci√≥n Las puertas de evacuaci√≥n tendr√°n un ancho libre m√≠nimo de 0,80 m, excepto las puertas de evacuaci√≥n de locales con ocupaci√≥n inferior a 50 personas, que podr√°n tener un ancho libre m√≠nimo de 0,60 m. 3.1.2 Puertas de salida de emergencia Las puertas de salida de emergencia tendr√°n un...</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 2 ‚Äî Score 2.333</div>\n",
       "                <div class='card-meta'>Source: cte_db_si_ejemplo.txt ‚Äî Section: SECCI√ìN 5</div>\n",
       "                <div class='card-body'>SECCI√ìN 5: INSTALACIONES DE PROTECCI√ìN 5.1 DETECCI√ìN DE INCENDIOS Los edificios de uso comercial con superficie superior a 500 m¬≤ dispondr√°n de sistema de detecci√≥n de incendios. 5.2 EXTINTORES Los extintores se situar√°n a una distancia m√°xima de 15 m desde cualquier punto del local.</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 3 ‚Äî Score 0.000</div>\n",
       "                <div class='card-meta'>Source: cte_db_si_ejemplo.txt</div>\n",
       "                <div class='card-body'>C√ìDIGO T√âCNICO DE LA EDIFICACI√ìN DOCUMENTO B√ÅSICO DB-SI: SEGURIDAD EN CASO DE INCENDIO SECCI√ìN</div>\n",
       "            </div>\n",
       "            \n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ STEP 2: LLM Response\n",
      "üìù Respuesta: La distancia m√°xima de evacuaci√≥n desde cualquier punto de un local hasta la salida m√°s pr√≥xima es:\n",
      "- 25 m en locales de uso residencial\n",
      "- 20 m en locales de uso comercial\n",
      "- 15 m en locales de uso industrial\n",
      "\n",
      "Fuente: SECCI√ìN 3: EVACUACI√ìN DE OCUPANTES ‚Äî 3.2.1 Distancia m√°xima de evacuaci√≥n (contexto proporcionado).\n"
     ]
    }
   ],
   "source": [
    "# Part 1: Keyword-only Search on TXT\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "print(\"\\n\" + \"#\" * 70)\n",
    "print(\"üîé Part 1: Keyword-only Search (TXT)\")\n",
    "print(\"#\" * 70)\n",
    "\n",
    "# Use absolute path from project root\n",
    "txt_path = ROOT / \"data/normativa/cte_db_si_ejemplo.txt\"\n",
    "if not txt_path.exists():\n",
    "    print(f\"‚ö†Ô∏è TXT not found at {txt_path}. Please ensure it exists.\")\n",
    "else:\n",
    "    raw = txt_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    # Very simple sectioning: split by headings like 'Secci√≥n X' or 'Cap√≠tulo X'\n",
    "    sections = re.split(r\"(?i)(?=\\b(secci√≥n|cap√≠tulo)\\s+\\w+)\", raw)\n",
    "    # Recombine to keep the heading paired with text\n",
    "    chunks = []\n",
    "    for i in range(0, len(sections), 2):\n",
    "        heading = sections[i].strip()\n",
    "        body = sections[i+1].strip() if i + 1 < len(sections) else \"\"\n",
    "        text = f\"{heading} {body}\".strip()\n",
    "        if text:\n",
    "            chunks.append(text)\n",
    "\n",
    "    def keyword_rank(query: str, texts):\n",
    "        q_words = [w for w in re.findall(r\"\\w+\", query.lower()) if len(w) > 2]\n",
    "        scored = []\n",
    "        for t in texts:\n",
    "            words = set(re.findall(r\"\\w+\", t.lower()))\n",
    "            overlap = sum(1 for w in q_words if w in words)\n",
    "            density = overlap / max(len(set(q_words)), 1)\n",
    "            score = overlap + 0.5 * density\n",
    "            scored.append((t, score))\n",
    "        return sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    def render_txt_chunks(results):\n",
    "        cards_html = []\n",
    "        for i, (text, score) in enumerate(results, 1):\n",
    "            # Best-effort parse of pseudo section heading\n",
    "            m = re.search(r\"(?i)\\b(secci√≥n|cap√≠tulo)\\s+([\\w.-]+)\", text)\n",
    "            section = m.group(0) if m else None\n",
    "            preview = textwrap.shorten(text.replace('\\n', ' '), width=380, placeholder='...')\n",
    "            card = f\"\"\"\n",
    "            <div class='card'>\n",
    "                <div class='card-title'>üìÑ Rank {i} ‚Äî Score {score:.3f}</div>\n",
    "                <div class='card-meta'>Source: cte_db_si_ejemplo.txt{f' ‚Äî Section: {section}' if section else ''}</div>\n",
    "                <div class='card-body'>{preview}</div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            cards_html.append(card)\n",
    "        html = f\"\"\"\n",
    "        <style>\n",
    "          .cards {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); gap: 12px; }}\n",
    "          .card {{ border: 1px solid #e5e7eb; border-radius: 8px; padding: 12px; background: #fff; }}\n",
    "          .card-title {{ font-weight: 600; margin-bottom: 6px; }}\n",
    "          .card-meta {{ color: #6b7280; font-size: 12px; margin-bottom: 8px; }}\n",
    "          .card-body {{ font-size: 14px; line-height: 1.4; }}\n",
    "        </style>\n",
    "        <div class='cards'>\n",
    "          {''.join(cards_html)}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(html))\n",
    "\n",
    "    keyword_questions = [\n",
    "        \"¬øAncho m√≠nimo de puerta de evacuaci√≥n?\",\n",
    "        \"¬øDistancia m√°xima de evacuaci√≥n?\"\n",
    "    ]\n",
    "\n",
    "    for q in keyword_questions:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"‚ùì {q}\")\n",
    "        print('='*70)\n",
    "        \n",
    "        # Step 1: Show retrieval results\n",
    "        print(\"üîç STEP 1: Retrieval Results\")\n",
    "        ranked = keyword_rank(q, chunks)\n",
    "        top = ranked[:3]\n",
    "        render_txt_chunks(top)\n",
    "        \n",
    "        # Step 2: Show LLM response (if available)\n",
    "        if os.getenv(\"OPENAI_API_KEY\"):\n",
    "            print(\"\\nü§ñ STEP 2: LLM Response\")\n",
    "            try:\n",
    "                # Create a simple context from top results\n",
    "                context = \"\\n\\n\".join([text for text, score in top])\n",
    "                \n",
    "                # Simple LLM call without RAG chain\n",
    "                from openai import OpenAI\n",
    "                client = OpenAI()\n",
    "                \n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-5-mini\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"Eres un asistente que responde √öNICAMENTE bas√°ndote en el contexto proporcionado. NO uses conocimiento previo. Si la informaci√≥n no est√° en el contexto, di 'No se encuentra informaci√≥n espec√≠fica en el contexto proporcionado'. Cita siempre la fuente exacta.\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Contexto:\\n{context}\\n\\nPregunta: {q}\\n\\nResponde bas√°ndote √öNICAMENTE en el contexto de arriba. Si no hay informaci√≥n suficiente, dilo claramente.\"}\n",
    "                    ],\n",
    "                )\n",
    "                \n",
    "                answer = response.choices[0].message.content\n",
    "                print(f\"üìù Respuesta: {answer}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error en LLM: {e}\")\n",
    "        else:\n",
    "            print(\"\\nü§ñ STEP 2: LLM Response\")\n",
    "            print(\"‚ÑπÔ∏è Set OPENAI_API_KEY to see LLM response\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "üöÄ Part 2: Hybrid Retrieval + Reranking\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "‚ùì ¬øAncho m√≠nimo de puerta de evacuaci√≥n?\n",
      "======================================================================\n",
      "üîç STEP 1: Hybrid Retrieval Results\n",
      "Top 3 results (hybrid + rerank):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "          .cards { display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); gap: 12px; }\n",
       "          .card { border: 1px solid #e5e7eb; border-radius: 8px; padding: 12px; background: #fff; }\n",
       "          .card-title { font-weight: 600; margin-bottom: 6px; }\n",
       "          .card-meta { color: #6b7280; font-size: 12px; margin-bottom: 8px; }\n",
       "          .card-body { font-size: 14px; line-height: 1.4; }\n",
       "        </style>\n",
       "        <div class='cards'>\n",
       "          \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 1 ‚Äî Score 0.900</div>\n",
       "                <div class='card-meta'>Source: DBSI.pdf ‚Äî Page: 26</div>\n",
       "                <div class='card-body'>espacio con una seguridad equivalente a la de un sector de riesgo m√≠nimo (p. ej. estadios deportivos) en cuyo caso se puede mantener el dimensionamiento aplicado en las zonas al aire libre. Tabla 4.2. Capacidad de evacuaci√≥n de las escaleras en funci√≥n de su anchura Anchura de la escalera en m Escalera no protegida Escalera protegida (evacuaci√≥n descendente o ascen-...</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 2 ‚Äî Score 0.850</div>\n",
       "                <div class='card-meta'>Source: DBSI.pdf ‚Äî Page: 15</div>\n",
       "                <div class='card-body'>tado 3 de la Secci√≥n SI 6 de este DB. (5) El recorrido por el interior de la zona de riesgo especial debe ser tenido en cuenta en el c√≥mputo de la longitud de los reco- rridos de evacuaci√≥n hasta las salidas de planta. Lo anterior no es aplicable al recorrido total desde un garaje de una vivie n- da unifamiliar hasta una salida de dicha vivienda, el cual no est√° limitado....</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 3 ‚Äî Score 0.800</div>\n",
       "                <div class='card-meta'>Source: DBSI.pdf ‚Äî Page: 42</div>\n",
       "                <div class='card-body'>- El recorrido de evacuaci√≥n desde cua lquier punto del escenario hasta alguna salida del sector no debe exceder de 25 m y las puertas de salida deben abrir en el sentido de la evacuaci√≥n. - Las pasarelas, galer√≠as o similares existentes para uso de actores o emple ados deben disponer de salidas de evacuaci√≥n. - Las pasarelas y escaleras del escenario deben tener una anchura...</div>\n",
       "            </div>\n",
       "            \n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ STEP 2: LLM Response\n",
      "üìù Respuesta: No se encuentra informaci√≥n espec√≠fica en el contexto proporcionado sobre el ancho m√≠nimo de las puertas de evacuaci√≥n. (Fuente: contexto proporcionado ‚Äî p√°rrafo ‚Äú- El recorrido de evacuaci√≥n ‚Ä¶ 25 m y las puertas de salida deben abrir en el sentido de la evacuaci√≥n.‚Äù)\n",
      "\n",
      "Observaciones relacionadas en el contexto:\n",
      "- Se indica que las puertas deben abrir en el sentido de la evacuaci√≥n y que el recorrido desde cualquier punto del escenario no debe exceder 25 m. (Fuente: contexto proporcionado ‚Äî mismo p√°rrafo citado).\n",
      "- El contexto s√≠ especifica anchuras m√≠nimas para otros elementos: ‚ÄúLas pasarelas y escaleras del escenario deben tener una anchura de 0,80 m, como m√≠nimo.‚Äù (Fuente: contexto proporcionado ‚Äî p√°rrafo ‚Äú- Las pasarelas y escaleras del escenario‚Ä¶‚Äù).\n",
      "- Tabla 4.2 aporta capacidades de evacuaci√≥n en funci√≥n de la anchura de las escaleras, pero no establece un ancho m√≠nimo de puerta. (Fuente: contexto proporcionado ‚Äî Tabla 4.2).\n",
      "\n",
      "======================================================================\n",
      "‚ùì ¬øDistancia m√°xima de evacuaci√≥n en edificios?\n",
      "======================================================================\n",
      "üîç STEP 1: Hybrid Retrieval Results\n",
      "Top 3 results (hybrid + rerank):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "          .cards { display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); gap: 12px; }\n",
       "          .card { border: 1px solid #e5e7eb; border-radius: 8px; padding: 12px; background: #fff; }\n",
       "          .card-title { font-weight: 600; margin-bottom: 6px; }\n",
       "          .card-meta { color: #6b7280; font-size: 12px; margin-bottom: 8px; }\n",
       "          .card-body { font-size: 14px; line-height: 1.4; }\n",
       "        </style>\n",
       "        <div class='cards'>\n",
       "          \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 1 ‚Äî Score 0.775</div>\n",
       "                <div class='card-meta'>Source: DBSI.pdf ‚Äî Page: 45</div>\n",
       "                <div class='card-body'>m2 y cuya superficie total no exceda de 50 m¬≤, como pueden ser las habitaciones de hotel, residencia u hospital, los despachos de oficinas, etc. Los puntos ocupables de todos los locales de riesgo e special y los de las zonas de ocupaci√≥n nula cuya superficie exceda de 50 m¬≤, se consideran origen de evacuaci√≥n y deben cumplir los l√≠mites que se esta- blecen para la longitud...</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 2 ‚Äî Score 0.750</div>\n",
       "                <div class='card-meta'>Source: DBSI.pdf ‚Äî Page: 28</div>\n",
       "                <div class='card-body'>nilla o pulsador conforme a la norma UNE-EN 179:2009, cuando se trate de la evacuaci√≥n de zonas ocupadas por personas que en su mayor√≠a est√©n familiarizados con la puerta considerada, as√≠ como en caso contrario, cuando se trate de puertas con apertura en el sentido de la evacuaci√≥n conforme al punto 3 siguiente, los de barra horizontal de empuje o de deslizamie nto conforme...</div>\n",
       "            </div>\n",
       "            \n",
       "            <div class='card'>\n",
       "                <div class='card-title'>üìÑ Rank 3 ‚Äî Score 0.575</div>\n",
       "                <div class='card-meta'>Source: DBSI.pdf ‚Äî Page: 27</div>\n",
       "                <div class='card-body'>Uso previsto(1) Condiciones seg√∫n tipo de protecci√≥n de la escalera h = altura de evacuaci√≥n de la escalera P = n√∫mero de personas a las que sirve en el conjunto de plantas No protegida Protegida(2) Especialmente protegida Escaleras para evacuaci√≥n descendente Residencial Vivienda h ‚â§ 14 m h ‚â§ 28 m Se admite en todo caso Administrativo, Docente, h ‚â§ 14 m h ‚â§ 28 m Comercial,...</div>\n",
       "            </div>\n",
       "            \n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ STEP 2: LLM Response\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Hybrid Retrieval + Simple Reranker (semantic + keywords)\n",
    "# Reload vectorstore if needed (fix for dependency issues)\n",
    "if rag is None or not hasattr(rag, 'vectorstore') or rag.vectorstore is None:\n",
    "    print(\"üîÑ Reloading vectorstore...\")\n",
    "    try:\n",
    "        # Try the standard approach first\n",
    "        from src.rag.vectorstore_manager import VectorstoreManager\n",
    "        vectorstore_path = ROOT / \"vectorstore/normativa_db\"\n",
    "        rag = VectorstoreManager(vectorstore_path)\n",
    "        rag.load_existing()\n",
    "        print(\"‚úÖ Vectorstore reloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Standard approach failed: {e}\")\n",
    "        print(\"üîÑ Trying minimal ChromaDB approach...\")\n",
    "        try:\n",
    "            # Fallback to minimal ChromaDB approach\n",
    "            import chromadb\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            \n",
    "            client = chromadb.PersistentClient(path=str(ROOT / \"vectorstore/normativa_db\"))\n",
    "            collection = client.get_collection(\"langchain\")\n",
    "            model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "            \n",
    "            # Create a minimal rag object\n",
    "            class MinimalRAG:\n",
    "                def __init__(self, client, collection, model):\n",
    "                    self.client = client\n",
    "                    self.collection = collection\n",
    "                    self.model = model\n",
    "                    self.vectorstore = None  # For compatibility\n",
    "                \n",
    "                def similarity_search(self, query, k=3):\n",
    "                    results = self.collection.query(\n",
    "                        query_texts=[query],\n",
    "                        n_results=k\n",
    "                    )\n",
    "                    # Convert to Document-like objects\n",
    "                    from langchain_core.documents import Document\n",
    "                    docs = []\n",
    "                    for i, content in enumerate(results['documents'][0]):\n",
    "                        metadata = results['metadatas'][0][i] if results['metadatas'][0] else {}\n",
    "                        docs.append(Document(page_content=content, metadata=metadata))\n",
    "                    return docs\n",
    "                \n",
    "                def similarity_search_with_score(self, query, k=3):\n",
    "                    results = self.collection.query(\n",
    "                        query_texts=[query],\n",
    "                        n_results=k\n",
    "                    )\n",
    "                    # Convert to Document-like objects with scores\n",
    "                    from langchain_core.documents import Document\n",
    "                    docs_with_scores = []\n",
    "                    for i, content in enumerate(results['documents'][0]):\n",
    "                        metadata = results['metadatas'][0][i] if results['metadatas'][0] else {}\n",
    "                        score = results['distances'][0][i] if results['distances'][0] else 0.0\n",
    "                        doc = Document(page_content=content, metadata=metadata)\n",
    "                        docs_with_scores.append((doc, score))\n",
    "                    return docs_with_scores\n",
    "            \n",
    "            rag = MinimalRAG(client, collection, model)\n",
    "            print(\"‚úÖ Minimal ChromaDB approach loaded successfully\")\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Minimal approach also failed: {e2}\")\n",
    "            rag = None\n",
    "\n",
    "if rag and (hasattr(rag, 'vectorstore') or hasattr(rag, 'collection')):\n",
    "    import re\n",
    "    from typing import List, Tuple\n",
    "\n",
    "    print(\"\\n\" + \"#\" * 70)\n",
    "    print(\"üöÄ Part 2: Hybrid Retrieval + Reranking\")\n",
    "    print(\"#\" * 70)\n",
    "\n",
    "    hybrid_questions = [\n",
    "        \"¬øAncho m√≠nimo de puerta de evacuaci√≥n?\",\n",
    "        \"¬øDistancia m√°xima de evacuaci√≥n en edificios?\"\n",
    "    ]\n",
    "\n",
    "    def keyword_score(text: str, query: str) -> float:\n",
    "        q_words = [w for w in re.findall(r\"\\w+\", query.lower()) if len(w) > 2]\n",
    "        if not q_words:\n",
    "            return 0.0\n",
    "        words = set(re.findall(r\"\\w+\", text.lower()))\n",
    "        overlap = sum(1 for w in q_words if w in words)\n",
    "        density = overlap / max(len(set(q_words)), 1)\n",
    "        return overlap + 0.5 * density\n",
    "\n",
    "    def render_hybrid(results: List[Tuple[object, float]]):\n",
    "        cards_html = []\n",
    "        for i, (doc, score) in enumerate(results, 1):\n",
    "            source = doc.metadata.get('source', 'Unknown')\n",
    "            page = doc.metadata.get('page', 'N/A')\n",
    "            section = doc.metadata.get('section')\n",
    "            section_str = f\" ‚Äî Section: {section}\" if section else \"\"\n",
    "            preview = textwrap.shorten(doc.page_content.replace('\\n', ' '), width=380, placeholder='...')\n",
    "            card = f\"\"\"\n",
    "            <div class='card'>\n",
    "                <div class='card-title'>üìÑ Rank {i} ‚Äî Score {score:.3f}</div>\n",
    "                <div class='card-meta'>Source: {source} ‚Äî Page: {page}{section_str}</div>\n",
    "                <div class='card-body'>{preview}</div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            cards_html.append(card)\n",
    "        html = f\"\"\"\n",
    "        <style>\n",
    "          .cards {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); gap: 12px; }}\n",
    "          .card {{ border: 1px solid #e5e7eb; border-radius: 8px; padding: 12px; background: #fff; }}\n",
    "          .card-title {{ font-weight: 600; margin-bottom: 6px; }}\n",
    "          .card-meta {{ color: #6b7280; font-size: 12px; margin-bottom: 8px; }}\n",
    "          .card-body {{ font-size: 14px; line-height: 1.4; }}\n",
    "        </style>\n",
    "        <div class='cards'>\n",
    "          {''.join(cards_html)}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(html))\n",
    "\n",
    "    for q in hybrid_questions:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"‚ùì {q}\")\n",
    "        print('='*70)\n",
    "\n",
    "        # Step 1: Show retrieval results\n",
    "        print(\"üîç STEP 1: Hybrid Retrieval Results\")\n",
    "        \n",
    "        # 1) Semantic candidates with scores (fallback to inverse-rank if unavailable)\n",
    "        semantic_results = []\n",
    "        try:\n",
    "            # Try to use vectorstore scores (works for both standard and minimal approaches)\n",
    "            if hasattr(rag, 'similarity_search_with_score'):\n",
    "                sem_with_scores = rag.similarity_search_with_score(q, k=8)\n",
    "                semantic_results = [(doc, float(score)) for doc, score in sem_with_scores]\n",
    "            else:\n",
    "                # Fallback for minimal approach\n",
    "                sem_docs = rag.similarity_search(q, k=8)\n",
    "                k = len(sem_docs) or 1\n",
    "                semantic_results = [(d, (k - i) / k) for i, d in enumerate(sem_docs)]\n",
    "            \n",
    "            # Convert distance (lower is better) to similarity-like score (higher is better)\n",
    "            if semantic_results:\n",
    "                max_s = max(s for _, s in semantic_results)\n",
    "                min_s = min(s for _, s in semantic_results)\n",
    "                denom = max(max_s - min_s, 1e-9)\n",
    "                semantic_results = [(d, 1.0 - ((s - min_s) / denom)) for d, s in semantic_results]\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error with vectorstore scores: {e}\")\n",
    "            # Fallback: inverse rank scoring\n",
    "            try:\n",
    "                sem_docs = rag.similarity_search(q, k=8)\n",
    "                k = len(sem_docs) or 1\n",
    "                semantic_results = [(d, (k - i) / k) for i, d in enumerate(sem_docs)]\n",
    "            except Exception as e2:\n",
    "                print(f\"‚ö†Ô∏è Error with similarity search: {e2}\")\n",
    "                print(\"Skipping this question...\")\n",
    "                continue\n",
    "\n",
    "        # 2) Keyword scoring for the same docs\n",
    "        kw_scores = {id(doc): keyword_score(doc.page_content, q) for doc, _ in semantic_results}\n",
    "        max_kw = max(kw_scores.values()) if kw_scores else 1.0\n",
    "\n",
    "        # 3) Combine (70% semantic, 30% keyword)\n",
    "        combined: List[Tuple[object, float]] = []\n",
    "        for doc, sem_s in semantic_results:\n",
    "            kw_norm = kw_scores.get(id(doc), 0.0) / max_kw if max_kw > 0 else 0.0\n",
    "            final = 0.7 * sem_s + 0.3 * kw_norm\n",
    "            combined.append((doc, final))\n",
    "\n",
    "        # 4) Sort and show top results\n",
    "        combined.sort(key=lambda x: x[1], reverse=True)\n",
    "        top = combined[:3]\n",
    "        print(f\"Top {len(top)} results (hybrid + rerank):\")\n",
    "        render_hybrid(top)\n",
    "        \n",
    "        # Step 2: Show LLM response (if available)\n",
    "        if os.getenv(\"OPENAI_API_KEY\"):\n",
    "            print(\"\\nü§ñ STEP 2: LLM Response\")\n",
    "            try:\n",
    "                # Create context from top results\n",
    "                context = \"\\n\\n\".join([doc.page_content for doc, score in top])\n",
    "                \n",
    "                # Simple LLM call\n",
    "                from openai import OpenAI\n",
    "                client = OpenAI()\n",
    "                \n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-5-mini\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"Eres un asistente que responde √öNICAMENTE bas√°ndote en el contexto proporcionado. NO uses conocimiento previo. Si la informaci√≥n no est√° en el contexto, di 'No se encuentra informaci√≥n espec√≠fica en el contexto proporcionado'. Cita siempre la fuente exacta (documento, p√°gina, secci√≥n).\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Contexto:\\n{context}\\n\\nPregunta: {q}\\n\\nResponde bas√°ndote √öNICAMENTE en el contexto de arriba. Si no hay informaci√≥n suficiente, dilo claramente.\"}\n",
    "                    ],\n",
    "                )\n",
    "                \n",
    "                answer = response.choices[0].message.content\n",
    "                print(f\"üìù Respuesta: {answer}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error en LLM: {e}\")\n",
    "        else:\n",
    "            print(\"\\nü§ñ STEP 2: LLM Response\")\n",
    "            print(\"‚ÑπÔ∏è Set OPENAI_API_KEY to see LLM response\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Part 2 skipped - vectorstore not available\")\n",
    "    if rag is None:\n",
    "        print(\"   Reason: rag object is None\")\n",
    "    elif not hasattr(rag, 'vectorstore') or rag.vectorstore is None:\n",
    "        print(\"   Reason: vectorstore is not initialized\")\n",
    "    else:\n",
    "        print(\"   Reason: unknown\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. ‚úÖ **LLM without RAG**: Shows generic responses without specific building code knowledge\n",
    "2. ‚úÖ **RAG combines retrieval + LLM generation**: Retrieval finds relevant chunks, LLM generates answers\n",
    "3. ‚úÖ **Keyword search**: Simple text matching with scores\n",
    "4. ‚úÖ **Hybrid retrieval**: Combines semantic similarity + keyword matching with reranking\n",
    "5. ‚úÖ **Visual results**: See exactly what chunks were retrieved with scores\n",
    "6. ‚úÖ **Source citations**: Always includes document, page, and section references\n",
    "\n",
    "**Key Insight**: RAG dramatically improves answer quality by providing specific, accurate information from your documents rather than relying on the LLM's general knowledge.\n",
    "\n",
    "**Next**: Tutorial 4 - Autonomous Agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Part 3: Build Vectorstore from `data/normativa/` for Agents\n",
    "\n",
    "This section builds/updates the vectorstore from all PDFs in `data/normativa/` (e.g., `DBSI.pdf`, `DccSUA.pdf`) and prepares a hybrid retriever suitable for agent usage.\n",
    "\n",
    "- Source folder: `data/normativa/`\n",
    "- Persist path: `vectorstore/normativa_db`\n",
    "- Output: a retriever function you can import and use in agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"#\" * 70)\n",
    "print(\"üß± Part 3: Build/Update Vectorstore from normativa/\")\n",
    "print(\"#\" * 70)\n",
    "\n",
    "norm_dir = ROOT / \"data/normativa\"\n",
    "vectorstore_path = ROOT / \"vectorstore/normativa_db\"\n",
    "\n",
    "print(f\"üìÇ Source dir: {norm_dir}\")\n",
    "print(f\"üíæ Persist dir: {vectorstore_path}\")\n",
    "\n",
    "# Ensure directories exist\n",
    "norm_dir.mkdir(parents=True, exist_ok=True)\n",
    "vectorstore_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Attempt standard pipeline first\n",
    "hybrid_retriever = None\n",
    "try:\n",
    "    from src.rag.vectorstore_manager import VectorstoreManager\n",
    "\n",
    "    manager = VectorstoreManager(vectorstore_path)\n",
    "    print(\"üîÅ Creating/refreshing vectorstore...\")\n",
    "    manager.create_from_pdfs(norm_dir)\n",
    "    print(\"üîÅ Loading vectorstore...\")\n",
    "    manager.load_existing()\n",
    "\n",
    "    # Prepare retriever: MMR with k=6 gives diverse candidates\n",
    "    hybrid_retriever = manager.get_retriever(k=6, search_type=\"mmr\")\n",
    "    print(\"‚úÖ Standard retriever ready (MMR, k=6)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Standard pipeline failed: {e}\")\n",
    "    print(\"üîÑ Falling back to minimal ChromaDB retriever\")\n",
    "    try:\n",
    "        import chromadb\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        from langchain_core.documents import Document\n",
    "\n",
    "        client = chromadb.PersistentClient(path=str(vectorstore_path))\n",
    "        # The default collection name used by LangChain Chroma is \"langchain\"\n",
    "        collection = client.get_or_create_collection(\"langchain\")\n",
    "        model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "        class MinimalRetriever:\n",
    "            def __init__(self, collection):\n",
    "                self.collection = collection\n",
    "            def invoke(self, query: str):\n",
    "                res = self.collection.query(query_texts=[query], n_results=6)\n",
    "                docs = []\n",
    "                for i, content in enumerate(res[\"documents\"][0]):\n",
    "                    meta = res[\"metadatas\"][0][i] if res[\"metadatas\"][0] else {}\n",
    "                    docs.append(Document(page_content=content, metadata=meta))\n",
    "                return docs\n",
    "\n",
    "        hybrid_retriever = MinimalRetriever(collection)\n",
    "        print(\"‚úÖ Minimal retriever ready (top-6)\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå Minimal retriever failed: {e2}\")\n",
    "        hybrid_retriever = None\n",
    "\n",
    "# Quick smoke test\n",
    "if hybrid_retriever is not None:\n",
    "    test_q = \"ancho m√≠nimo puerta evacuaci√≥n\"\n",
    "    print(f\"\\nüß™ Smoke test query: {test_q}\")\n",
    "    try:\n",
    "        # Works for both retriever types (`invoke`) or .get_relevant_documents\n",
    "        results = None\n",
    "        if hasattr(hybrid_retriever, \"invoke\"):\n",
    "            results = hybrid_retriever.invoke(test_q)\n",
    "        else:\n",
    "            results = hybrid_retriever.get_relevant_documents(test_q)\n",
    "        n = len(results) if results else 0\n",
    "        print(f\"‚úÖ Retriever returned {n} docs\")\n",
    "        if results:\n",
    "            print(\"üìÑ Preview:\")\n",
    "            for d in results[:2]:\n",
    "                src = d.metadata.get(\"source\", \"Unknown\")\n",
    "                page = d.metadata.get(\"page\", \"?\")\n",
    "                print(f\" - {src} (page {page}): {d.page_content[:120]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Smoke test failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå No retriever available\")\n",
    "\n",
    "# Expose a simple function for agents\n",
    "AGENT_RETRIEVER = hybrid_retriever\n",
    "print(\"\\nüì¶ AGENT_RETRIEVER is ready for import/use in agents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
